<!DOCTYPE html>
<html>
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
    <meta name="description" content="PhD Student">
    <meta name="author" content="Joanne Lin">
    
    <title>Multi-Scale Denoising in the Feature Space for Low-Light Instance Segmentation</title>
    <link rel="stylesheet" href="https://stackpath.bootstrapcdn.com/bootstrap/4.5.0/css/bootstrap.min.css" integrity="sha384-9aIt2nRpC12Uk9gS9baDl411NQApFmC26EwAOH8WgZl5MYYxFfc+NcPb1dKGj7Sk" crossorigin="anonymous">
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/normalize/5.0.0/normalize.min.css">
    <link rel="stylesheet" href="http://localhost:4000/assets/css/style.css">
    <link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.1.0/css/all.css">
    <link rel="stylesheet" href="https://cdn.rawgit.com/jpswalsh/academicons/master/css/academicons.min.css">

    <!-- you should probably put some google analytics / meta bits and pieces
        here : PRH 
    <meta property="og:title" content="Paul Hill's Website"> etc.
      <script async src="https://www.googletagmanager.com/gtag/js?id=??????????"></script>
    <script>
        window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());

        gtag('config', '??????????');
    </script>
        -->
</head>


<body id="page-top">
    <div class="page-container">
    <div class="inner">
        <div class="container">
            <div class="row">
                <div class="row vertical-align">
                    <div class="col-md-10">
                        <div class="title">
                            <h1>Multi-Scale Denoising in the Feature Space for Low-Light Instance Segmentation</h1>
                            <div class="container-sm">
                                <!-- TODO: create for loop to loop over profiles -->
                                <div class="row justify-content-md-center">
                                    
                                    <div class="col-sm-auto">
                                        <p><a href="https://joannelin168.github.io/">J. Lin</a></p>
                                        <p></p>
                                    </div>
                                    
                                    <div class="col-sm-auto">
                                        <p><a href="https://pui-nantheera.github.io/">N. Anatrasirichai</a></p>
                                        <p></p>
                                    </div>
                                    
                                    <div class="col-sm-auto">
                                        <p><a href="https://david-bull.github.io/">D. Bull</a></p>
                                        <p></p>
                                    </div>
                                    
                                    <div class="col-sm-auto">
                                        <p><a href=""></a></p>
                                        <p></p>
                                    </div>
                                    
                                </div>
                            </div>
                        </div>
                    </div>

        <div class="col-md-2">
            <p><a href='https://www.bristol.ac.uk'><img src="/assets/images/uob-logo.svg" width="100%" height="20%" alt=""></a></p>
            <p><a href='https://www.bristol.ac.uk/vision-institute'><img src="/assets/images/bvilogo.svg" width="100%" height="20%" alt=""></a></p>
                <p><a href='https://vilab.blogs.bristol.ac.uk'><img src="/assets/images/VIL_logo.svg" width="100%" height="20%" alt=""></a></p>
            
                    </div>
                </div>
            </div>
        </div>
        <div class="container-md">
            <h2>About</h2>
            <p>We propose a novel generic block for denoising the feature maps of low-light images, which can be easily integrated into existing instance segmentation frameworks.</p>

            <dl>
                
                    <dt>Funders</dt><dd>MyWorld Strength in Places</dd>
                
                
            </dl>

        </div>
        <hr />

        <!-- Research content -->
        <div class="container-md">
            <h2 id="links">Links</h2>
            
            <a href="https://ieeexplore.ieee.org/document/10889336">[PDF]</a>
            
            
            <a href="https://arxiv.org/abs/2402.18307">[ArXiv]</a>
            
            
            
            <a href="https://github.com/JoanneLin168/weighted-non-local">[Code]</a>
            
        </div>
        <hr />

        <div class="container-md">
            <h2>Abstract</h2>
            <p><p>Instance segmentation for low-light imagery remains largely unexplored due to the challenges imposed by such conditions, for example shot noise due to low photon count, color distortions and reduced contrast. In this paper, we propose an end-to-end solution to address this challenging task. Our proposed method implements weighted non-local blocks (wNLB) in the feature extractor. This integration enables an inherent denoising process at the feature level. As a result, our method eliminates the need for aligned ground truth images during training, thus supporting training on real-world low-light datasets. We introduce additional learnable weights at each layer in order to enhance the networkâ€™s adaptability to real-world noise characteristics, which affect different feature scales in different ways. Experimental results on several object detectors show that the proposed method outperforms the pretrained networks with an Average Precision (AP) improvement of at least +7.6, with the introduction of wNLB further enhancing AP by upto +1.3.</p>
</p> 
        </div>
        <hr />

        
        <div class="container-md">
            <h2 id="poster">Poster</h2>
            <p><a href="/assets/publications/LoIS_poster.pdf"><img src="/assets/publications/LoIS_poster.jpg" alt="Poster" width=300 class="center"/></a></p>
            <p>(Click on the image to view the poster in higher quality)</p>
        </div>
        <hr />
        

        <div class="container-md">
            <h2>Citation</h2>
            <p>If you use our work in your research, please cite using the following BibTeX entry:</p>
            <pre class="citation">@INPROCEEDINGS{lin2025lowlightsegm,
    author={Lin, Joanne and Anantrasirichai, Nantheera and Bull, David},
    booktitle={ICASSP 2025 - 2025 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
    title={Multi-Scale Denoising in the Feature Space for Low-Light Instance Segmentation}, 
    year={2025},
    volume={},
    number={},
    pages={1-5},
    doi={10.1109/ICASSP49660.2025.10889336}}
</pre>
        </div>
    </div>
</div>

</body>
</html>
