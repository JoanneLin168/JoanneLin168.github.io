<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.9.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-08-18T14:52:31+01:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">Joanne Lin Research</title><subtitle>PhD Student</subtitle><author><name>Joanne Lin</name></author><entry><title type="html">Towards a General-Purpose Zero-Shot Synthetic Low-Light Image and Video Pipeline</title><link href="http://localhost:4000/2025/10/29/NoiseDEN.html" rel="alternate" type="text/html" title="Towards a General-Purpose Zero-Shot Synthetic Low-Light Image and Video Pipeline" /><published>2025-10-29T00:00:00+00:00</published><updated>2025-10-29T00:00:00+00:00</updated><id>http://localhost:4000/2025/10/29/NoiseDEN</id><content type="html" xml:base="http://localhost:4000/2025/10/29/NoiseDEN.html">&lt;p&gt;Low-light conditions pose significant challenges for both human and machine annotation. This in turn has led to a lack of research into machine understanding for low-light images and (in particular) videos. A common approach is to apply annotations obtained from high quality datasets to synthetically created low light versions. In addition, these approaches are often limited through the use of unrealistic noise models. In this paper, we propose a new Degradation Estimation Network (DEN), which synthetically generates realistic standard RGB (sRGB) noise without the requirement for camera metadata. This is achieved by estimating the parameters of physics-informed noise distributions, trained in a self-supervised manner. This zero-shot approach allows our method to generate synthetic noisy content with a diverse range of realistic noise characteristics, unlike other methods which focus on recreating the noise characteristics of the training data. We evaluate our proposed synthetic pipeline using various methods trained on its synthetic data for typical low-light tasks including synthetic noise replication, video enhancement, and object detection, showing improvements of up to 24% KLD, 21% LPIPS, and 62% AP_{50-95}, respectively.&lt;/p&gt;</content><author><name>Joanne Lin</name></author><summary type="html">Low-light conditions pose significant challenges for both human and machine annotation. This in turn has led to a lack of research into machine understanding for low-light images and (in particular) videos. A common approach is to apply annotations obtained from high quality datasets to synthetically created low light versions. In addition, these approaches are often limited through the use of unrealistic noise models. In this paper, we propose a new Degradation Estimation Network (DEN), which synthetically generates realistic standard RGB (sRGB) noise without the requirement for camera metadata. This is achieved by estimating the parameters of physics-informed noise distributions, trained in a self-supervised manner. This zero-shot approach allows our method to generate synthetic noisy content with a diverse range of realistic noise characteristics, unlike other methods which focus on recreating the noise characteristics of the training data. We evaluate our proposed synthetic pipeline using various methods trained on its synthetic data for typical low-light tasks including synthetic noise replication, video enhancement, and object detection, showing improvements of up to 24% KLD, 21% LPIPS, and 62% AP_{50-95}, respectively.</summary></entry><entry><title type="html">Enhancing low-light instance segmentation through feature-level denoising</title><link href="http://localhost:4000/2025/05/29/LoIST.html" rel="alternate" type="text/html" title="Enhancing low-light instance segmentation through feature-level denoising" /><published>2025-05-29T00:00:00+01:00</published><updated>2025-05-29T00:00:00+01:00</updated><id>http://localhost:4000/2025/05/29/LoIST</id><content type="html" xml:base="http://localhost:4000/2025/05/29/LoIST.html">&lt;p&gt;Instance segmentation accurately delineates the precise boundaries of each distinct object in an image or video. However, performing this task in low-light conditions presents challenges due to issues such as shot noise from low photon counts, color distortions, and reduced contrast. In this work, we propose a plug-and-play solution designed to address these complexities. Our approach integrates weighted non-local blocks (wNLB) into the feature extractor, enabling inherent denoising at the feature level. The proposed method incorporates learnable weights at each layer, allowing the network to adapt to the varying noise characteristics across different feature scales. We demonstrate that our wNLB improves the performance of object detectors and trackers when compared to pretrained networks.&lt;/p&gt;</content><author><name>Joanne Lin</name></author><summary type="html">Instance segmentation accurately delineates the precise boundaries of each distinct object in an image or video. However, performing this task in low-light conditions presents challenges due to issues such as shot noise from low photon counts, color distortions, and reduced contrast. In this work, we propose a plug-and-play solution designed to address these complexities. Our approach integrates weighted non-local blocks (wNLB) into the feature extractor, enabling inherent denoising at the feature level. The proposed method incorporates learnable weights at each layer, allowing the network to adapt to the varying noise characteristics across different feature scales. We demonstrate that our wNLB improves the performance of object detectors and trackers when compared to pretrained networks.</summary></entry><entry><title type="html">Multi-Scale Denoising in the Feature Space for Low-Light Instance Segmentation</title><link href="http://localhost:4000/2025/03/07/LoIS.html" rel="alternate" type="text/html" title="Multi-Scale Denoising in the Feature Space for Low-Light Instance Segmentation" /><published>2025-03-07T00:00:00+00:00</published><updated>2025-03-07T00:00:00+00:00</updated><id>http://localhost:4000/2025/03/07/LoIS</id><content type="html" xml:base="http://localhost:4000/2025/03/07/LoIS.html">&lt;p&gt;Instance segmentation for low-light imagery remains largely unexplored due to the challenges imposed by such conditions, for example shot noise due to low photon count, color distortions and reduced contrast. In this paper, we propose an end-to-end solution to address this challenging task. Our proposed method implements weighted non-local blocks (wNLB) in the feature extractor. This integration enables an inherent denoising process at the feature level. As a result, our method eliminates the need for aligned ground truth images during training, thus supporting training on real-world low-light datasets. We introduce additional learnable weights at each layer in order to enhance the network’s adaptability to real-world noise characteristics, which affect different feature scales in different ways. Experimental results on several object detectors show that the proposed method outperforms the pretrained networks with an Average Precision (AP) improvement of at least +7.6, with the introduction of wNLB further enhancing AP by upto +1.3.&lt;/p&gt;</content><author><name>Joanne Lin</name></author><summary type="html">Instance segmentation for low-light imagery remains largely unexplored due to the challenges imposed by such conditions, for example shot noise due to low photon count, color distortions and reduced contrast. In this paper, we propose an end-to-end solution to address this challenging task. Our proposed method implements weighted non-local blocks (wNLB) in the feature extractor. This integration enables an inherent denoising process at the feature level. As a result, our method eliminates the need for aligned ground truth images during training, thus supporting training on real-world low-light datasets. We introduce additional learnable weights at each layer in order to enhance the network’s adaptability to real-world noise characteristics, which affect different feature scales in different ways. Experimental results on several object detectors show that the proposed method outperforms the pretrained networks with an Average Precision (AP) improvement of at least +7.6, with the introduction of wNLB further enhancing AP by upto +1.3.</summary></entry></feed>